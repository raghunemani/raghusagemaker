{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.5.12\n",
      "  latest version: 4.7.12\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/ec2-user/anaconda3/envs/python3\n",
      "\n",
      "  added / updated specs: \n",
      "    - xgboost\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    xgboost-0.90               |   py36he1b5a44_4          11 KB  conda-forge\n",
      "    mkl_random-1.0.2           |           py36_0         1.3 MB  conda-forge\n",
      "    openssl-1.0.2t             |       h14c3975_0         3.1 MB  conda-forge\n",
      "    tbb-2019.9                 |       hc9558a2_0         1.4 MB  conda-forge\n",
      "    py-xgboost-0.90            |           py36_4          73 KB  conda-forge\n",
      "    _py-xgboost-mutex-2.0      |            cpu_0           8 KB  conda-forge\n",
      "    tbb4py-2019.9              |   py36hc9558a2_0         245 KB  conda-forge\n",
      "    libxgboost-0.90            |       he1b5a44_4         2.4 MB  conda-forge\n",
      "    mkl_fft-1.0.10             |           py36_0         650 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         9.2 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "    _py-xgboost-mutex: 2.0-cpu_0             conda-forge\n",
      "    libxgboost:        0.90-he1b5a44_4       conda-forge\n",
      "    py-xgboost:        0.90-py36_4           conda-forge\n",
      "    tbb:               2019.9-hc9558a2_0     conda-forge\n",
      "    tbb4py:            2019.9-py36hc9558a2_0 conda-forge\n",
      "    xgboost:           0.90-py36he1b5a44_4   conda-forge\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "    ca-certificates:   2019.5.15-0                       --> 2019.9.11-hecc5488_0 conda-forge\n",
      "    certifi:           2019.6.16-py36_0                  --> 2019.9.11-py36_0     conda-forge\n",
      "    mkl_fft:           1.0.1-py36h3010b51_0              --> 1.0.10-py36_0        conda-forge\n",
      "    mkl_random:        1.0.1-py36h629b387_0              --> 1.0.2-py36_0         conda-forge\n",
      "    openssl:           1.0.2s-h7b6447c_0                 --> 1.0.2t-h14c3975_0    conda-forge\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "xgboost-0.90         | 11 KB     | ##################################### | 100% \n",
      "mkl_random-1.0.2     | 1.3 MB    | ##################################### | 100% \n",
      "openssl-1.0.2t       | 3.1 MB    | ##################################### | 100% \n",
      "tbb-2019.9           | 1.4 MB    | ##################################### | 100% \n",
      "py-xgboost-0.90      | 73 KB     | ##################################### | 100% \n",
      "_py-xgboost-mutex-2. | 8 KB      | ##################################### | 100% \n",
      "tbb4py-2019.9        | 245 KB    | ##################################### | 100% \n",
      "libxgboost-0.90      | 2.4 MB    | ##################################### | 100% \n",
      "mkl_fft-1.0.10       | 650 KB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "# install xgboost\n",
    "!conda install -y -c conda-forge xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import boto3\n",
    "import re\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import xgboost as xgb\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iris Classification dataset\n",
    "Input Features:\n",
    "sepal_length, sepal_width, petal_length, petal_width\n",
    "\n",
    "Target Feature:\n",
    "Iris plant class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['encoded_class', 'sepal_length','sepal_width','petal_length','petal_width']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the class labels to integers\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('iris_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['encoded_class'] = le.transform(df['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and validation set\n",
    "### Target variables are the first columns followed by input features:\n",
    "class, sepal_length, sepal_width, petal_length, petal_width\n",
    "\n",
    "### Training and validation files do not have column headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training = 70% of the data\n",
    "# Validation = 30% of the data\n",
    "# Randomize the dataset\n",
    "np.random.seed(5)\n",
    "l = list(df.index)\n",
    "np.random.shuffle(l)\n",
    "df = df.loc[l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = df.shape[0]\n",
    "train = int(.7* rows)\n",
    "test = rows - train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the Training dataset\n",
    "df[:train].to_csv('iris_train.csv',index=False,header=False, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the validation dataset\n",
    "df[train:].to_csv('iris_validation.csv',index=False, header=False, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write columns list\n",
    "with open('iris_columns_list.txt','w') as f:\n",
    "    f.write(','.join(columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost \n",
    "### Multiclass classification using xgboost in the local mode\n",
    "This is testing the parameters before running the model in Sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a variable for the files that have been generated\n",
    "column_list_file = 'iris_columns_list.txt'\n",
    "train_file = 'iris_train.csv'\n",
    "validation_file = 'iris_validation.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ''\n",
    "with open(column_list_file,'r') as f:\n",
    "    columns = f.read().split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and validation data frame. Columns list is needed\n",
    "# as the files do not have column headers\n",
    "df_train = pd.read_csv(train_file,names=columns)\n",
    "df_validation = pd.read_csv(validation_file, names=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.iloc[:,1:]\n",
    "y_train = df_train.iloc[:,0].ravel()\n",
    "\n",
    "X_validation = df_validation.iloc[:,1:]\n",
    "y_validation = df_validation.iloc[:,0].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = xgb.XGBClassifier(objective=\"multi:softmax\",\n",
    "                               num_classes=3,\n",
    "                               n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.fit(X_train, y_train,\n",
    "               eval_set=[(X_train, y_train), (X_validation, y_validation)],\n",
    "               eval_metric=['mlogloss'],\n",
    "               early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_result = classifier.evals_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_rounds = range(len(eval_result['validation_0']['mlogloss']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(training_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=training_rounds, y=eval_result['validation_0']['mlogloss'], label='Training Error')\n",
    "plt.scatter(x=training_rounds, y=eval_result['validation_1']['mlogloss'], label='Validation Error')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('LogLoss')\n",
    "plt.title('Training vs Validation Error')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.plot_importance(classifier)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(validation_file, names=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['predicted_class'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the performance of actual and predicted class\n",
    "plt.scatter(df.index, df['encoded_class'], label='Actual')\n",
    "plt.scatter(df.index, df['predicted_class'], label='Predicted', marker='^')\n",
    "plt.xlabel('Sample')\n",
    "plt.ylabel('Class')\n",
    "plt.legend(loc=1)\n",
    "plt.yticks([0,1,2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(\n",
    "      df['encoded_class'],\n",
    "      df['predicted_class'],\n",
    "      labels=[0,1,2],\n",
    "      target_names=['Iris-setosa','Iris-versicolor', 'Iris-virginica']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sagemaker deployment of the XGBoost model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = 'napa-ml-sagemaker'\n",
    "training_file_key = 'iris/iris_train.csv'\n",
    "validation_file_key = 'iris/iris_validation.csv'\n",
    "\n",
    "s3_model_output_location = r's3://{0}/iris/model'.format(bucket_name)\n",
    "s3_training_file_location = r's3://{0}/{1}'.format(bucket_name, training_file_key)\n",
    "s3_validation_file_location = r's3://{0}/{1}'.format(bucket_name, validation_file_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s3_model_output_location)\n",
    "print(s3_training_file_location)\n",
    "print(s3_validation_file_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write file to S3 and then read the file\n",
    "# files are referred to as objects in S3\n",
    "# file name is referred to as key name in S3\n",
    "\n",
    "def write_to_s3(filename, bucket, key):\n",
    "    with open(filename,'rb') as f:\n",
    "        return boto3.Session().resource('s3').Bucket(bucket).Object(key).upload_fileobj(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_s3('iris_train.csv', bucket_name, training_file_key)\n",
    "write_to_s3('iris_validation.csv', bucket_name, validation_file_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and validation have a docker image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish a Sagemaker session with AWS\n",
    "sess = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the role that has the permission to train, deploy models in Sagemaker\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:There is a more up to date SageMaker XGBoost image.To use the newer image, please set 'repo_version'='0.90-1. For example:\n",
      "\tget_image_uri(region, 'xgboost', '0.90-1').\n"
     ]
    }
   ],
   "source": [
    "# Get the container\n",
    "containers = sagemaker.amazon.amazon_estimator.get_image_uri(\n",
    "              sess.boto_region_name,\n",
    "              \"xgboost\",\n",
    "              \"latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Sagemaker container:\n",
      "811284229777.dkr.ecr.us-east-1.amazonaws.com/xgboost:latest (us-east-1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Using Sagemaker container:\\n{} ({})\".format(containers, sess.boto_region_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = sagemaker.estimator.Estimator(containers, role,\n",
    "                                          train_instance_count=1,\n",
    "                                          train_instance_type='ml.m4.xlarge',\n",
    "                                          output_path=s3_model_output_location,\n",
    "                                          sagemaker_session=sess,\n",
    "                                          base_job_name='xgboost-iris-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.set_hyperparameters(max_depth=5,\n",
    "                              objective=\"multi:softmax\",\n",
    "                              num_class=3,\n",
    "                              num_round=50,\n",
    "                              early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 5,\n",
       " 'objective': 'multi:softmax',\n",
       " 'num_class': 3,\n",
       " 'num_round': 50,\n",
       " 'early_stopping_rounds': 10}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.hyperparameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify the data channels that show the training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_input_config = sagemaker.session.s3_input(s3_data=s3_training_file_location,\n",
    "                                                   content_type='csv',\n",
    "                                                   s3_data_type ='S3Prefix'\n",
    "                                                   )\n",
    "validation_input_config = sagemaker.session.s3_input(s3_data=s3_validation_file_location,\n",
    "                                                     content_type = 'csv',\n",
    "                                                     s3_data_type ='S3Prefix')\n",
    "\n",
    "data_channels = {'train':training_input_config, 'validation':validation_input_config}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-11 16:01:27 Starting - Starting the training job...\n",
      "2019-11-11 16:01:29 Starting - Launching requested ML instances......\n",
      "2019-11-11 16:02:32 Starting - Preparing the instances for training...\n",
      "2019-11-11 16:03:27 Downloading - Downloading input data......\n",
      "2019-11-11 16:04:25 Training - Training image download completed. Training in progress.\n",
      "2019-11-11 16:04:25 Uploading - Uploading generated training model\u001b[31mArguments: train\u001b[0m\n",
      "\u001b[31m[2019-11-11:16:04:21:INFO] Running standalone xgboost training.\u001b[0m\n",
      "\u001b[31m[2019-11-11:16:04:21:INFO] File size need to be processed in the node: 0.0mb. Available memory size in the node: 8582.96mb\u001b[0m\n",
      "\u001b[31m[2019-11-11:16:04:21:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[31m[16:04:21] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[31m[16:04:21] 105x4 matrix with 420 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[31m[2019-11-11:16:04:21:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[31m[16:04:21] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[31m[16:04:21] 45x4 matrix with 180 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[31m[16:04:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[31m[16:04:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 0 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[31m[16:04:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[31m[0]#011train-merror:0.019048#011validation-merror:0.044444\u001b[0m\n",
      "\u001b[31mMultiple eval metrics have been passed: 'validation-merror' will be used for early stopping.\n",
      "\u001b[0m\n",
      "\u001b[31mWill train until validation-merror hasn't improved in 10 rounds.\u001b[0m\n",
      "\u001b[31m[16:04:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[31m[16:04:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 0 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[31m[16:04:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[31m[1]#011train-merror:0.019048#011validation-merror:0.044444\u001b[0m\n",
      "\u001b[31m[16:04:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[31m[16:04:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 0 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[31m[16:04:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[31m[2]#011train-merror:0.019048#011validation-merror:0.044444\u001b[0m\n",
      "\u001b[31m[16:04:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[31m[16:04:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[31m[16:04:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 0 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[31m[3]#011train-merror:0.009524#011validation-merror:0.044444\u001b[0m\n",
      "\u001b[31m[16:04:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[31m[16:04:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 0 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[31m[16:04:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 0 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[31m[4]#011train-merror:0.009524#011validation-merror:0.044444\u001b[0m\n",
      "\u001b[31m[16:04:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[31m[16:04:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 0 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[31m[16:04:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 0 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[31m[5]#011train-merror:0.009524#011validation-merror:0.044444\u001b[0m\n",
      "\u001b[31m[16:04:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[31m[16:04:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 0 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[31m[16:04:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[31m[6]#011train-merror:0.009524#011validation-merror:0.044444\u001b[0m\n",
      "\u001b[31m[16:04:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[31m[16:04:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 0 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[31m[16:04:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 0 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[31m[7]#011train-merror:0.009524#011validation-merror:0.044444\u001b[0m\n",
      "\u001b[31m[16:04:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[31m[16:04:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 0 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[31m[16:04:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[31m[8]#011train-merror:0.009524#011validation-merror:0.044444\u001b[0m\n",
      "\u001b[31m[16:04:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[31m[16:04:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 0 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[31m[16:04:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[31m[9]#011train-merror:0.009524#011validation-merror:0.044444\u001b[0m\n",
      "\u001b[31m[16:04:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[31m[16:04:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[16:04:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[31m[10]#011train-merror:0.009524#011validation-merror:0.044444\u001b[0m\n",
      "\u001b[31mStopping. Best iteration:\u001b[0m\n",
      "\u001b[31m[0]#011train-merror:0.019048#011validation-merror:0.044444\n",
      "\u001b[0m\n",
      "\n",
      "2019-11-11 16:04:57 Completed - Training job completed\n",
      "Training seconds: 90\n",
      "Billable seconds: 90\n"
     ]
    }
   ],
   "source": [
    "estimator.fit(data_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "predictor = estimator.deploy(initial_instance_count=1,\n",
    "                             instance_type='ml.m4.xlarge',\n",
    "                             endpoint_name = 'xgboost-iris-v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acquire real time endpoint\n",
    "endpoint_name = 'xgboost-iris-v1'\n",
    "predictor = sagemaker.predictor.RealTimePredictor(endpoint=endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import csv_serializer, json_deserializer\n",
    "\n",
    "predictor.content_type = 'text/csv'\n",
    "predictor.serializer = csv_serializer\n",
    "predictor.deserializer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test prediction on the validation dataset\n",
    "df_all = pd.read_csv('iris_validation.csv',\n",
    "                     names=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['encoded_class', 'sepal_length', 'sepal_width', 'petal_length',\n",
       "       'petal_width'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "# Need to pass an array to the prediction\n",
    "arr_test = df_all.as_matrix(['sepal_length','sepal_width','petal_length','petal_width'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for arr in np.array_split(arr_test,10):\n",
    "    result = predictor.predict(arr)\n",
    "    result = result.decode(\"utf-8\")\n",
    "    result = result.split(',')\n",
    "    for r in result:\n",
    "        predictions.append(int(float(r)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(['Iris-setosa', 'Iris-versicolor','Iris-virginica'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['class'] = le.inverse_transform(df_all.encoded_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['predicted_class'] = le.inverse_transform(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encoded_class</th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>class</th>\n",
       "      <th>predicted_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>6.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   encoded_class  sepal_length  sepal_width  petal_length  petal_width  \\\n",
       "0              1           5.8          2.7           4.1          1.0   \n",
       "1              0           4.8          3.4           1.6          0.2   \n",
       "2              1           6.0          2.2           4.0          1.0   \n",
       "3              2           6.4          3.1           5.5          1.8   \n",
       "4              2           6.7          2.5           5.8          1.8   \n",
       "\n",
       "             class  predicted_class  \n",
       "0  Iris-versicolor  Iris-versicolor  \n",
       "1      Iris-setosa      Iris-setosa  \n",
       "2  Iris-versicolor  Iris-versicolor  \n",
       "3   Iris-virginica   Iris-virginica  \n",
       "4   Iris-virginica   Iris-virginica  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix - Actula versus Predicted\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predicted_class</th>\n",
       "      <th>Iris-setosa</th>\n",
       "      <th>Iris-versicolor</th>\n",
       "      <th>Iris-virginica</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Iris-setosa</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Iris-versicolor</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Iris-virginica</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predicted_class  Iris-setosa  Iris-versicolor  Iris-virginica\n",
       "class                                                        \n",
       "Iris-setosa               16                0               0\n",
       "Iris-versicolor            0               10               1\n",
       "Iris-virginica             0                1              17"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Confusion matrix - Actula versus Predicted')\n",
    "pd.crosstab(df_all['class'], df_all['predicted_class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        16\n",
      "Iris-versicolor       0.91      0.91      0.91        11\n",
      " Iris-virginica       0.94      0.94      0.94        18\n",
      "\n",
      "      micro avg       0.96      0.96      0.96        45\n",
      "      macro avg       0.95      0.95      0.95        45\n",
      "   weighted avg       0.96      0.96      0.96        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as metrics\n",
    "print(metrics.classification_report(df_all['class'], df_all['predicted_class']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
